{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwuLWtYq2iqu"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import argparse\n",
        "import time\n",
        "import re\n",
        "\n",
        "from dataset import get_data\n",
        "\n",
        "\n",
        "def get_response(args, user_request, max_len, temp):\n",
        "    responese = openai.Completion.create(\n",
        "        engine = args.model_name,\n",
        "        prompt = user_request,\n",
        "        max_tokens = max_len,\n",
        "        n = 1,\n",
        "        temperature = temp\n",
        "    )\n",
        "\n",
        "    return responese\n",
        "\n",
        "def convert_to_submit_file(api_result: list = []):\n",
        "    answer_start = api_result.find(\"Answer: \")\n",
        "    if answer_start != -1:\n",
        "        answer_end = api_result.find(\",\", answer_start)\n",
        "        answer_part = api_result[answer_start + len(\"Answer: \"):answer_end]\n",
        "\n",
        "        if any(c.isalpha() for c in answer_part):\n",
        "            answer = answer_part[0:answer_part.find(\")\")]\n",
        "        else:\n",
        "            answer = answer_part\n",
        "        return answer.lower()\n",
        "    else:\n",
        "        answer = api_result\n",
        "        return answer.lower()\n",
        "    return 'Nan'\n",
        "\n",
        "\n",
        "\n",
        "def main(args):\n",
        "    with open(\"openai_api_key.txt\", \"r\") as f:\n",
        "        openai.api_key = f.readline()\n",
        "        test_examples = get_data(args.data)\n",
        "        results = []\n",
        "        with open('./results/results.txt', 'r') as read:\n",
        "            results = read.readlines()\n",
        "        curr_indx = 1\n",
        "        last_indx = len(results)\n",
        "        print(\"Last request: \", last_indx)\n",
        "        with open('./results/results.txt', 'a') as f:\n",
        "            for problem in test_examples:\n",
        "                prompt = \"Help me choose the correct answer to the following problem. Note that you only need to return the letters corresponding to the chosen answer. \\nQuestion:\"\n",
        "                ques = problem[\"Problem\"]\n",
        "                max_len = 20\n",
        "                temp = 0.2\n",
        "                user_request = prompt + ques\n",
        "                responese = {}\n",
        "                if curr_indx > last_indx:\n",
        "                    while 'id' not in responese:\n",
        "                        try:\n",
        "                            t1 = time.time()\n",
        "                            responese = get_response(args, user_request, max_len, temp)\n",
        "                            #print(user_request)\n",
        "                            t2 = time.time()\n",
        "                            time_request = t2 - t1\n",
        "                            answer = responese.choices[0].text\n",
        "                            #results.append([answer, time_request])\n",
        "                        except:\n",
        "                            print(\"Waiting...\")\n",
        "                            time.sleep(20)\n",
        "                            continue\n",
        "                    print(f\"Time request for {problem['id']}: {time_request}, answer: {answer}\")\n",
        "                    choose = convert_to_submit_file(answer)\n",
        "                    f.write(choose + '\\t' + str(time_request) + '\\n')\n",
        "\n",
        "                curr_indx += 1\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "\t\t\"--model_name\", type=str,\n",
        "\t\tdefault=\"text-davinci-003\",\n",
        "        help= \"Name to request model from openai\"\n",
        "\t)\n",
        "    parser.add_argument(\n",
        "\t\t\"--data\", type=str,\n",
        "\n",
        "\t\tdefault=\"./data/test.json\",\n",
        "\t\thelp=\"Path to data test\"\n",
        "\t)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "    main(args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "import openai"
      ],
      "metadata": {
        "id": "JeevXSVz6ZRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1ddaa9-5225-41f7-e48a-8cd862ee1afe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"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\"\n",
        "model  = \"text-davinci-003\"\n",
        "def get_response(user_question):\n",
        "    response = openai.Completion.create(\n",
        "        engine = model,\n",
        "        prompt = user_question,\n",
        "        max_tokens = 1024,\n",
        "        n = 1,\n",
        "        temperature = 0.5\n",
        "    )\n",
        "\n",
        "    response_text = response.choices[0].text\n",
        "    return response_text\n",
        "prompt = \"Là một toán học, hãy trả lời các câu hỏi trắc nghiệm sau\"\n",
        "\n",
        "ques = \"a man whose bowling average is 12.4 , takes 5 wickets for 26 runs and there by decreases his average by 0.4 . the number of wickets taken by him before his last match is ? a ) 82 , b ) 83 , c ) 84 , d ) 85 , e ) 86\"\n",
        "user_question = prompt + ques\n",
        "response_text = get_response(user_question)\n",
        "response_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Z3EHGHDH2vrS",
        "outputId": "b50c1479-6ae2-443b-d2f1-3cc10f4d2c9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nC. 84'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}